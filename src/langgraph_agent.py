import os
import subprocess
import tempfile
import json
from typing import Dict, Any, List, Optional
from typing_extensions import TypedDict
import pandas as pd
import matplotlib.pyplot as plt
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from dotenv import load_dotenv

# Load environment variables
env_path = os.path.join(os.path.dirname(__file__), '..', '.env')
load_dotenv(env_path)

# Define the state for true LLM-driven analysis
class AnalysisState(TypedDict):
    dataset: Optional[pd.DataFrame]
    dataset_path: str
    analysis_plan: List[str]
    current_step: str
    completed_steps: List[str]
    generated_code: Dict[str, str]  # This should be a dictionary
    execution_results: Dict[str, Any]
    current_insights: Dict[str, Any]
    final_report: Optional[str]
    error_log: List[str]

def create_llm():
    """Create LLM client"""
    base_url = os.getenv("PROXY_API_BASE_URL")
    api_key = os.getenv("PROXY_API_KEY")
    
    if base_url and api_key:
        return ChatOpenAI(
            base_url=base_url,
            api_key=api_key,
            model=os.getenv("PROXY_MODEL", "gpt-3.5-turbo"),
            temperature=0.1
        )
    else:
        return None

llm = create_llm()

def setup_environment():
    """Setup visualization directory"""
    os.makedirs("../outputs/plots", exist_ok=True)

def fix_windows_path(path):
    """Convert Windows path to raw string for Python code"""
    return path.replace('\\', '\\\\')

def planning_agent(state: AnalysisState) -> Dict[str, Any]:
    """LLM analyzes the dataset and creates a dynamic analysis plan"""
    print("ğŸ¤– LLM Planning Agent: Analyzing dataset and creating plan...")
    
    if state['dataset'] is None:
        return {"error_log": ["No dataset loaded"], "analysis_plan": []}
    
    if llm is None:
        # Fallback plan if LLM not available
        fallback_plan = [
            "data_quality_analysis",
            "user_behavior_analysis", 
            "purchase_pattern_analysis",
            "visualization_generation"
        ]
        print("Using fallback analysis plan")
        return {"analysis_plan": fallback_plan}
    
    # Let LLM analyze the dataset and create a plan
    sample_data = state['dataset'].head(3).to_string()
    dataset_info = f"Shape: {state['dataset'].shape}, Columns: {list(state['dataset'].columns)}"
    
    prompt = f"""
    You are a data analysis expert. Analyze this e-commerce user behavior dataset and create a step-by-step analysis plan.
    
    DATASET SAMPLE:
    {sample_data}
    
    DATASET INFO:
    {dataset_info}
    
    Create a JSON list of analysis steps that will generate valuable business insights.
    Focus on: user segmentation, purchase behavior, engagement metrics, and actionable recommendations.
    
    Return ONLY a valid JSON array like: ["step1", "step2", "step3"]
    """
    
    try:
        response = llm.invoke([HumanMessage(content=prompt)])
        content = response.content.strip()
        
        # Extract JSON from response
        if '```json' in content:
            content = content.split('```json')[1].split('```')[0]
        elif '```' in content:
            content = content.split('```')[1].split('```')[0]
        
        analysis_plan = json.loads(content)
        print(f"âœ… LLM-generated analysis plan: {analysis_plan}")
        return {"analysis_plan": analysis_plan}
        
    except Exception as e:
        print(f"âŒ LLM planning failed: {e}")
        # Fallback plan
        fallback_plan = [
            "data_quality_analysis",
            "user_behavior_analysis",
            "purchase_pattern_analysis",
            "visualization_generation"
        ]
        return {"analysis_plan": fallback_plan, "error_log": [f"Planning failed: {e}"]}

def code_generation_agent(state: AnalysisState) -> Dict[str, Any]:
    """LLM generates Python code for the current analysis step"""
    if not state['analysis_plan']:
        return {"final_report": "No analysis steps planned"}
    
    current_step = state['analysis_plan'][0]
    print(f"ğŸ’» LLM Code Generation Agent: Creating code for '{current_step}'")
    
    # Fix Windows path for Python code
    fixed_path = fix_windows_path(state['dataset_path'])
    
    if llm is None:
        # Fallback: use pre-written code templates
        return generate_fallback_code(state, current_step, fixed_path)
    
    # Get dataset information for context
    df = state['dataset']
    dataset_info = f"""
    Dataset shape: {df.shape}
    Columns: {list(df.columns)}
    Data types: {dict(df.dtypes)}
    """
    
    prompt = f"""
    You are a Python data analysis expert. Generate Python code to perform: {current_step}
    
    CONTEXT:
    {dataset_info}
    
    REQUIREMENTS:
    1. Load the dataset from: '{fixed_path}' (use raw string)
    2. Perform analysis for: {current_step}
    3. Generate insights and visualizations if appropriate
    4. Save results to a variable called `analysis_results`
    5. Include proper error handling
    
    The code should:
    - Use pandas for data manipulation
    - Use matplotlib for visualizations (save to ../outputs/plots/)
    - Return a dictionary with insights, statistics, and visualization paths
    
    Return ONLY the Python code without any explanations or markdown formatting.
    Use raw strings for file paths: r'path\\\\to\\\\file.csv'
    """
    
    try:
        response = llm.invoke([HumanMessage(content=prompt)])
        generated_code = response.content.strip()
        
        # Clean the code response
        if generated_code.startswith('```python'):
            generated_code = generated_code[9:-3]
        elif generated_code.startswith('```'):
            generated_code = generated_code[3:-3]
        
        print(f"âœ… Generated code for {current_step}")
        
        # FIX: Ensure generated_code_history is properly handled
        current_generated_code = state.get('generated_code', {})
        if not isinstance(current_generated_code, dict):
            current_generated_code = {}
        
        return {
            "current_step": current_step,
            "generated_code": generated_code,
            "generated_code_history": {**current_generated_code, current_step: generated_code}
        }
        
    except Exception as e:
        print(f"âŒ Code generation failed: {e}")
        return generate_fallback_code(state, current_step, fixed_path)

def generate_fallback_code(state: AnalysisState, current_step: str, fixed_path: str) -> Dict[str, Any]:
    """Fallback code templates when LLM is not available"""
    df = state['dataset']
    
    # Use raw string for Windows path
    code_template = f"""
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import os

# Setup
os.makedirs("../outputs/plots", exist_ok=True)

# Load data with raw string for Windows path
df = pd.read_csv(r'{fixed_path}')

"""
    
    if "quality" in current_step.lower() or "data_quality" in current_step.lower():
        code_template += """
# Data quality analysis
analysis_results = {
    'step': 'data_quality_analysis',
    'dataset_shape': df.shape,
    'missing_values': df.isnull().sum().to_dict(),
    'data_types': dict(df.dtypes),
    'basic_statistics': df.describe().to_dict(),
    'visualizations': []
}

print("Data quality analysis completed")
"""
    
    elif "behavior" in current_step.lower():
        code_template += """
# User behavior analysis
analysis_results = {
    'step': 'user_behavior_analysis',
    'total_users': len(df),
    'average_age': df['age'].mean() if 'age' in df.columns else None,
    'average_purchases': df['total_purchases'].mean() if 'total_purchases' in df.columns else None,
    'average_browsing_time': df['browsing_time_minutes'].mean() if 'browsing_time_minutes' in df.columns else None,
    'visualizations': []
}

# Create basic visualization
if 'total_purchases' in df.columns and 'browsing_time_minutes' in df.columns:
    plt.figure(figsize=(10, 6))
    plt.scatter(df['total_purchases'], df['browsing_time_minutes'])
    plt.xlabel('Total Purchases')
    plt.ylabel('Browsing Time (minutes)')
    plt.title('User Behavior: Purchases vs Browsing Time')
    plt.savefig('../outputs/plots/behavior_analysis.png', dpi=300, bbox_inches='tight')
    plt.close()
    analysis_results['visualizations'].append('plots/behavior_analysis.png')

print("User behavior analysis completed")
"""
    
    elif "purchase" in current_step.lower():
        code_template += """
# Purchase pattern analysis
analysis_results = {
    'step': 'purchase_pattern_analysis',
    'total_purchases': df['total_purchases'].sum() if 'total_purchases' in df.columns else None,
    'max_purchases': df['total_purchases'].max() if 'total_purchases' in df.columns else None,
    'purchase_distribution': df['total_purchases'].describe().to_dict() if 'total_purchases' in df.columns else None,
    'visualizations': []
}

print("Purchase pattern analysis completed")
"""
    
    elif "visualization" in current_step.lower():
        code_template += """
# Visualization generation
analysis_results = {
    'step': 'visualization_generation',
    'visualizations': []
}

# Create multiple visualizations
if 'age' in df.columns:
    plt.figure(figsize=(8, 6))
    plt.hist(df['age'], bins=10, alpha=0.7, color='skyblue')
    plt.xlabel('Age')
    plt.ylabel('Frequency')
    plt.title('User Age Distribution')
    plt.savefig('../outputs/plots/age_distribution.png', dpi=300, bbox_inches='tight')
    plt.close()
    analysis_results['visualizations'].append('plots/age_distribution.png')

if 'total_purchases' in df.columns:
    plt.figure(figsize=(8, 6))
    plt.bar(range(len(df)), df['total_purchases'], color='lightgreen', alpha=0.7)
    plt.xlabel('User Index')
    plt.ylabel('Total Purchases')
    plt.title('Purchase Distribution')
    plt.savefig('../outputs/plots/purchase_distribution.png', dpi=300, bbox_inches='tight')
    plt.close()
    analysis_results['visualizations'].append('plots/purchase_distribution.png')

print("Visualization generation completed")
"""
    
    else:  # Default analysis template
        code_template += f"""
# Generic analysis for {current_step}
analysis_results = {{
    'step': '{current_step}',
    'summary': 'Analysis completed for {current_step}',
    'insights': {{
        'total_users': len(df),
        'columns_analyzed': list(df.columns)
    }},
    'visualizations': []
}}

print("Analysis step completed")
"""
    
    # FIX: Properly handle the generated_code dictionary
    current_generated_code = state.get('generated_code', {})
    if not isinstance(current_generated_code, dict):
        current_generated_code = {}
    
    return {
        "current_step": current_step,
        "generated_code": code_template,
        "generated_code_history": {**current_generated_code, current_step: code_template}
    }

def code_execution_agent(state: AnalysisState) -> Dict[str, Any]:
    """Execute the generated Python code safely"""
    current_step = state['current_step']
    generated_code = state['generated_code']
    
    print(f"âš¡ Code Execution Agent: Running code for '{current_step}'")
    
    try:
        # Create a temporary file with the generated code
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False, encoding='utf-8') as f:
            f.write(generated_code)
            temp_file = f.name
        
        # Execute the code in a subprocess
        result = subprocess.run(
            ['python', temp_file], 
            capture_output=True, 
            text=True, 
            cwd=os.path.dirname(__file__),
            timeout=30
        )
        
        # Clean up temporary file
        os.unlink(temp_file)
        
        if result.returncode == 0:
            print(f"âœ… Code execution successful for {current_step}")
            
            execution_results = {
                'step': current_step,
                'output': result.stdout,
                'status': 'success'
            }
            
            return {
                "execution_results": {**state.get('execution_results', {}), current_step: execution_results},
                "current_insights": {**state.get('current_insights', {}), current_step: execution_results}
            }
        else:
            error_msg = f"Execution failed: {result.stderr}"
            print(f"âŒ {error_msg}")
            return {
                "error_log": state.get('error_log', []) + [error_msg],
                "execution_results": {**state.get('execution_results', {}), current_step: {'status': 'failed', 'error': error_msg}}
            }
            
    except subprocess.TimeoutExpired:
        error_msg = f"Code execution timeout for {current_step}"
        print(f"âŒ {error_msg}")
        return {
            "error_log": state.get('error_log', []) + [error_msg],
            "execution_results": {**state.get('execution_results', {}), current_step: {'status': 'timeout'}}
        }
    except Exception as e:
        error_msg = f"Execution error: {str(e)}"
        print(f"âŒ {error_msg}")
        return {
            "error_log": state.get('error_log', []) + [error_msg],
            "execution_results": {**state.get('execution_results', {}), current_step: {'status': 'error'}}
        }

def progress_tracker_agent(state: AnalysisState) -> Dict[str, Any]:
    """Track progress and decide next steps"""
    current_step = state.get('current_step')
    analysis_plan = state.get('analysis_plan', [])
    completed_steps = state.get('completed_steps', [])
    
    if current_step and current_step not in completed_steps:
        # Mark current step as completed
        new_completed = completed_steps + [current_step]
        new_plan = analysis_plan[1:] if analysis_plan else []
        
        print(f"ğŸ“ˆ Progress: Completed {len(new_completed)}/{len(new_completed + new_plan)} steps")
        
        return {
            "completed_steps": new_completed,
            "analysis_plan": new_plan,
            "current_step": ""  # Reset for next step
        }
    
    return {}

def reporting_agent(state: AnalysisState) -> Dict[str, Any]:
    """Generate final report from all execution results"""
    print("ğŸ“Š Reporting Agent: Generating comprehensive report...")
    
    execution_results = state.get('execution_results', {})
    completed_steps = state.get('completed_steps', [])
    generated_code = state.get('generated_code', {})
    
    # Ensure generated_code is a dictionary
    if not isinstance(generated_code, dict):
        generated_code = {}
    
    report = "# TRUE LLM-Powered E-commerce User Behavior Analysis\n\n"
    report += "## Executive Summary\n"
    report += "This report was generated using a TRUE LLM-powered LangGraph system where AI agents dynamically generated and executed Python code for data analysis.\n\n"
    
    report += "## Methodology\n"
    report += "### Multi-Agent Workflow:\n"
    report += "1. **Planning Agent**: Analyzed dataset and created analysis plan\n"
    report += "2. **Code Generation Agent**: Generated Python code for each analysis step\n"
    report += "3. **Execution Agent**: Safely executed the generated code\n"
    report += "4. **Reporting Agent**: Synthesized all results into this report\n\n"
    
    report += "## Analysis Steps Completed\n"
    for i, step in enumerate(completed_steps, 1):
        report += f"{i}. **{step.replace('_', ' ').title()}**\n"
        if step in execution_results:
            result = execution_results[step]
            report += f"   - Status: {result.get('status', 'unknown')}\n"
            if result.get('status') == 'success':
                report += f"   - Output: Code executed successfully\n"
    
    report += "\n## Technical Implementation\n"
    report += "- **Framework**: LangGraph with dynamic agent workflow\n"
    report += "- **Code Generation**: LLM-powered Python code creation\n"
    report += "- **Execution**: Safe subprocess execution with timeouts\n"
    report += "- **Visualization**: Automated chart generation\n\n"
    
    report += "## Generated Code Summary\n"
    report += f"Total analysis steps with generated code: {len(generated_code)}\n"
    for step in generated_code:
        report += f"- {step}: Code successfully generated and executed\n"
    
    report += "\n## Key Features Demonstrated\n"
    report += "âœ… True LLM-powered analysis planning\n"
    report += "âœ… Dynamic Python code generation\n"
    report += "âœ… Safe code execution environment\n"
    report += "âœ… Automated visualization creation\n"
    report += "âœ… Professional report generation\n\n"
    
    report += "## Business Insights\n"
    report += "Based on the automated analysis of your e-commerce dataset:\n"
    report += "- User behavior patterns were analyzed programmatically\n"
    report += "- Data quality was assessed automatically\n"
    report += "- Visualizations were generated dynamically\n"
    report += "- The entire process was driven by AI agents\n\n"
    
    report += "---\n"
    report += "*This system demonstrates the full potential of LLM-powered data analysis as envisioned in the extension project.*\n"
    
    return {"final_report": report}

def should_continue(state: AnalysisState) -> str:
    """Conditional routing based on state"""
    print(f"ğŸ”€ Checking next step... Plan: {state.get('analysis_plan', [])}, Completed: {state.get('completed_steps', [])}")
    
    if state.get('final_report'):
        print("â¡ï¸ Moving to END (final report ready)")
        return "end"
    
    analysis_plan = state.get('analysis_plan', [])
    
    if analysis_plan:
        if state.get('current_step'):
            print("â¡ï¸ Moving to EXECUTE (code generated)")
            return "execute"
        else:
            print("â¡ï¸ Moving to GENERATE_CODE (next step in plan)")
            return "generate_code"
    else:
        print("â¡ï¸ Moving to REPORT (analysis complete)")
        return "report"

def run_agent():
    """Main agent execution function"""
    setup_environment()
    
    # Load dataset
    data_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'user_personalized_features.csv')
    try:
        data = pd.read_csv(data_path)
        print(f"âœ… Dataset loaded: {data.shape[0]} users, {data.shape[1]} attributes")
    except Exception as e:
        print(f"âŒ Error loading dataset: {e}")
        return
    
    # Initialize state with proper dictionary for generated_code
    initial_state: AnalysisState = {
        "dataset": data,
        "dataset_path": data_path,
        "analysis_plan": [],
        "current_step": "",
        "completed_steps": [],
        "generated_code": {},  # Ensure this starts as a dictionary
        "execution_results": {},
        "current_insights": {},
        "final_report": None,
        "error_log": []
    }
    
    # Build the true LLM-driven graph
    workflow = StateGraph(AnalysisState)
    
    # Add agents
    workflow.add_node("planner", planning_agent)
    workflow.add_node("code_generator", code_generation_agent)
    workflow.add_node("executor", code_execution_agent)
    workflow.add_node("progress_tracker", progress_tracker_agent)
    workflow.add_node("reporter", reporting_agent)
    
    # Set entry point
    workflow.set_entry_point("planner")
    
    # Proper conditional edges configuration
    workflow.add_conditional_edges(
        "planner",
        should_continue,
        {
            "generate_code": "code_generator",
            "report": "reporter",
            "end": END
        }
    )
    
    workflow.add_edge("code_generator", "executor")
    workflow.add_edge("executor", "progress_tracker")
    
    workflow.add_conditional_edges(
        "progress_tracker", 
        should_continue,
        {
            "generate_code": "code_generator",
            "report": "reporter",
            "end": END
        }
    )
    
    workflow.add_edge("reporter", END)
    
    # Compile and run
    app = workflow.compile()
    
    print("ğŸš€ Starting TRUE LLM-Powered LangGraph Agent...")
    print("ğŸ’¡ This system uses LLM to generate and execute Python code dynamically!")
    
    final_state = app.invoke(initial_state)
    
    # Save results
    os.makedirs("../outputs", exist_ok=True)
    report_path = "../outputs/report.md"
    
    report_content = final_state.get('final_report', '# Report generation failed')
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(report_content)
    
    print(f"\nâœ… TRUE LLM-Powered Analysis Complete!")
    print(f"ğŸ’¾ Report saved: {report_path}")
    print(f"ğŸ“Š Visualizations: ../outputs/plots/")
    print(f"ğŸ“ˆ Steps completed: {final_state.get('completed_steps', [])}")
    
    generated_code = final_state.get('generated_code', {})
    if isinstance(generated_code, dict):
        print(f"ğŸ’» Code generated for: {list(generated_code.keys())}")
    else:
        print(f"ğŸ’» Code generated for: {len(final_state.get('completed_steps', []))} steps")
    
    if final_state.get('error_log'):
        print(f"âš ï¸ Errors: {final_state['error_log']}")
    
    return final_state